ics 142 winter 2004 midterm study guide 
midterm study guide 
ics
142
winter
2004
news
course
reference
schedule
lab
manual
ics
142
newsgroup
alex
ics
142
winter
2004
midterm
study
guide
introduction
study
guide
summary
material
covered
lecture
thusfar
estimated
end
conclusion
wednesday's
lecture
material
covered
end
wednesday's
lecture
readings
correspond
will
included
midterm
even
listed
hazard
presented
posting
study
guide
early
thought
rather
estimated
version
earlier
perfect
version
later
intend
include
questions
midterm
testing
tiny
details
textbook
covered
lecture
responsible
assigned
readings
broad
ideas
important
points
readings
fair
game
exam
even
cover
lecture
included
material
study
guide
however
things
specifically
listed
limits
exam
dfa
minimization
algorithm
will
slightly
reduce
amount
reading
material
need
study
study
guide
big
picture
compiler
compiler
program
takes
program
source
language
input
emits
equivalent
program
target
language
output
notion
equivalent
program
needs
defined
equivalent
program
one
may
may
perform
specific
set
operations
order
will
generate
observable
result
original
one
general
like
compilers
make
improvements
programs
long
observable
result
improvements
generally
called
optimizations
course
need
think
carefully
compiler
writers
constitutes
observable
result
compilers
pretty
big
job
like
large
piece
software
makes
sense
separate
concerns
splitting
program
smaller
pieces
many
years
typical
design
strategy
split
compiler
two
pieces
front
end
back
end
front
end
focused
validating
source
program
understanding
meaning
back
end
concerned
generating
equivalent
program
target
language
output
front
end
simplified
version
source
program
often
called
intermediate
representation
ir
name
intermediate
representation
arises
neither
source
target
program
used
within
compiler
back
end
assumes
ir
well
formed
since
built
front
end
rather
fallible
human
programmer
approach
couple
clear
advantages
separation
concerns
jobs
performed
front
back
ends
largely
distinct
makes
good
software
engineering
sense
separate
reuse
building
library
front
ends
build
kind
ir
library
back
ends
emit
target
programs
various
architectures
using
kind
ir
one
can
easily
build
large
collection
compilers
simply
connection
different
front
ends
different
back
ends
recent
overall
design
strategy
includes
third
component
optimizer
optimizers
take
input
program
kind
ir
generate
output
better
version
program
kind
ir
either
kind
different
kind
constitutes
better
matter
debate
many
attributes
program
optimize
execution
speed
code
size
power
consumption
three
examples
surprisingly
passing
ir's
phases
allows
plug
together
front
end
optimizer
sequence
optimizers
back
end
yield
compiler
along
way
compiler
may
use
global
data
structures
symbol
tables
record
information
program
determined
different
phases
desirable
properties
compiler
ideally
like
compilers
exhibit
certain
desirable
properties
execution
speed
compiled
code
necessary
like
compiler
able
generate
speed
efficient
code
possible
size
compiled
code
also
like
compiler
able
generate
space
efficient
code
possible
oftentimes
represents
tradeoff
whereby
give
execution
speed
size
vice
versa
ideally
programmers
able
specify
important
instruct
compiler
trade
one
error
reporting
like
compiler
emit
understandable
error
messages
error
encountered
source
program
easier
said
done
support
debugging
debugging
partially
supported
compiler
use
symbolic
graphical
debugger
say
compiled
program
compiler
will
need
instructed
include
information
like
variable
names
function
signatures
generated
code
information
generally
left
compiled
program
execution
speed
compiler
things
equal
fast
compiler
better
slow
one
course
often
willing
use
slower
compiler
gives
us
desirable
benefits
details
front
end
compiler
front
end's
performs
following
tasks
reads
source
program
input
source
file
validates
source
program
ensuring
legal
program
programming
language
expected
comes
understanding
meaning
source
program
conveys
meaning
concisely
possible
building
returning
intermediate
representation
passing
later
stages
compilation
extracting
conveying
meaning
source
program
big
job
makes
sense
divide
smaller
ones
first
stage
called
scanning
compiler
takes
program
stream
characters
turns
stream
meaningful
patterns
called
tokens
rest
compiler
need
concern
every
character
input
program
instead
deals
larger
abstractions
identifiers
string
literals
next
stage
called
parsing
compiler
takes
stream
tokens
discovers
whether
tokens
form
syntactically
legal
program
stage
syntax
form
program
checked
semantics
meaning
program
checked
later
third
stage
called
semantic
analysis
context
sensitive
analysis
stage
meaning
program
determined
semantic
errors
using
undeclared
variables
detected
scanning
scanner's
job
recognize
patterns
input
program
use
patterns
group
characters
togethers
tokens
words
scanner
unconcerned
whether
sequence
tokens
makes
sense
concerned
recognizing
legal
tokens
one
way
solve
problem
build
hand
coded
scanner
write
sequence
conditional
statements
loops
detect
patterns
plausible
simple
language
can
become
tedious
big
hurry
theory
helps
us
solve
problem
better
way
deterministic
finite
automaton
dfa
five
tuple
£m
£_
s0
sf
finite
set
states?
alphabet
character
set
used
dfa£_
function
value
£_
indicates
state
dfa
move
state
sees
character
input
s0
start
statesf
set
final
states
dfa
begins
start
state
consuming
input
symbol
order
using
£_
function
determine
state
move
consuming
input
dfa
final
state
input
accepted
dfa
final
state
input
rejected
say
set
strings
accepted
dfa
language
denoted
implementing
dfa
computer
program
turns
relatively
straightforward
declare
variable
say
integer
keep
track
current
state
initialize
variable
start
state
process
input
characters
loop
setting
state
variable
new
state
character
easily
look
value
£_
function
store
two
dimensional
array
states
rows
input
characters
groups
input
characters
columns
trying
use
dfa's
directly
build
scanner
realize
two
things
implementing
dfa
way
tedious
specifying
£_
function
two
dimensional
array
will
painful
tool
help
even
tool
take
definition
dfa
input
spit
code
output
problem
quite
semantic
distance
problem
trying
solve
specifying
patterns
interested
recognizing
formalism
using
solve
ideally
rather
specify
patterns
intuitive
notation
let
tool
convert
dfa
spit
code
regular
expressions
regular
expression
defines
language
alphabet
£m
£`
regular
expression
denoting
set
containing
empty
string
character
£m
regular
expression
denotes
language
consisting
string
containing
concatenation
two
regular
expressions
denoted
rs
regular
expression
resulting
regular
expression
describes
language
strings
consist
string
followed
string
alternation
two
regular
expressions
denoted
regular
expression
resulting
regular
expression
describes
language
strings
¡å
kleene
closure
regular
expression
denoted
regular
expression
resulting
regular
expression
describes
language
strings
consist
zero
occurrences
strings
concatenated
together
simplify
notation
specify
operator
precedences
follows
kleene
closure
highest
precedenceconcatenation
next
highest
precedencealternation
lowest
precedenceparentheses
used
override
precedence
much
way
use
mathematics
programming
languages
complete
definition
regular
expressions
mathematical
sense
use
shorthands
sometimes
use
notation
denote
language
strings
consist
one
occurrences
strings
concatenated
together
words
rr
use
notation
denote
language
strings
consist
zero
one
occurrences
strings
words
£`
character
classes
shorthands
set
characters
example
character
class
0
9
denotes
one
occurrence
character
either
0
1
2
9
naturally
can
combine
character
classes
operators
yield
regular
expressions
like
0
9
denote
patterns
examples
two
regular
expressions
recognize
either
word
public
protected
private
public
protected
privatep
ublic
otected
ivate
regular
expression
recognizes
integers
without
leading
zeroes
0
1
9
0
9
regular
exrpession
recognizes
real
number
constants
hypothetical
programming
language
including
scientific
notation
0
9
0
9
0
9
regular
expressions
much
intuitive
notation
humans
use
specify
patterns
unfortunately
make
lousy
implementation
strategy
fortunately
theory
can
help
regular
expressions
can
converted
dfa's
mechanically
implies
tool
following
take
regular
expression
input
convert
regular
expression
dfa
emit
code
implements
dfa
converting
regular
expressions
dfa's
useful
theoretical
result
regular
expressions
dfa's
describe
set
languages
words
language
can
described
regular
expression
can
recognized
dfa
vice
versa
algorithm
given
book
converting
dfa
regular
expression
will
covered
exam
implies
must
possible
convert
regular
expression
dfa
unfortunately
needs
done
multiple
steps
first
step
convert
regular
expression
intermediate
form
called
non
deterministic
finite
automata
nfa
nfa
just
like
dfa
two
differences
can
specify
one
transition
state
given
input
character
can
specify
£`
transitions
can
followed
without
consuming
input
character
perhaps
surprisingly
even
differences
nfa's
theoretically
powerful
dfa's
words
language
can
recognized
nfa
can
also
recognized
dfa
implies
nfa
can
converted
dfa
nfa
processes
input
string
differently
dfa
dfa
exactly
one
state
given
time
begins
start
state
upon
consuming
input
character
moves
exactly
one
state
nfa
set
states
given
time
begins
£`
closure
start
state
start
state
along
states
can
reached
start
state
taking
£`
transitions
upon
consuming
input
character
moves
£`
closure
states
reaches
following
transitions
character
states
nfa
can
constructed
regular
expression
mechanically
using
construction
called
thompson's
construction
noted
constructions
can
used
construct
nfa
regular
expression
thompson's
construction
used
automated
tools
can
implemented
efficiently
others
principle
built
upon
nfa
constructs
intermediate
ones
constructs
single
start
state
single
final
state
transitions
entering
start
state
transitions
leaving
final
state
thompson's
construction
proceeds
taking
regular
expression
applying
operators
precedence
order
applying
operator
requires
taking
nfa
operands
pasting
together
one
nfa
using
template
templates
shown
textbook
shown
lecture
applying
templates
operators
regular
expression
resulting
nfa
recognizes
language
described
regular
expression
nfa
unfortunately
good
implementation
tool
problem
convert
dfa
using
subset
construction
subset
construction
builds
dfa
simulates
behavior
nfa
state
dfa
corresponds
subset
states
nfa
total
number
states
dfa
size
power
set
states
nfa
practice
turn
much
smaller
since
states
reached
every
state
dfa
transition
input
character
state
s'
nfa
go
subset
states
corresponding
subset
states
corresponding
s'
input
character
constructing
dfa
using
subset
construction
can
run
dfa
minimization
algorithm
minimize
number
states
dfa
algorithm
covered
lecture
will
covered
exam
constructing
automated
scanner
dfa
takes
input
string
ultimately
says
accept
reject
output
need
tool
takes
input
program
stream
characters
returns
stream
tokens
words
need
dfa
recognize
many
words
just
one
using
automated
tool
jflex
specify
list
regular
expressions
specify
patterns
like
scanner
recognize
tool
will
things
use
alternation
'
'
build
one
regular
expression
patterns
convert
regular
expression
nfa
using
thompson's
construction
convert
nfa
dfa
using
subset
construction
minimize
number
dfa
states
using
minimization
algorithm
emit
code
recognizes
patterns
using
dfa
one
approach
involve
using
dfa
recognizer
whenever
final
state
reached
dfa
consider
consumed
input
token
return
token
go
back
start
state
problem
approach
due
overlapping
patterns
result
odd
behavior
example
word
fork
java
program
considered
identifier
pattern
matcher
recognize
keyword
followed
identifier
solve
problems
like
automated
scanners
search
longest
possible
pattern
instead
using
following
approach
continue
running
dfa
consuming
input
reaches
situation
output
transition
current
character
point
dfa
final
state
recognized
pattern
represented
final
state
backtrack
input
consumed
encounter
final
state
pattern
instead
never
final
state
input
begin
lexeme
error
will
reported
since
one
pattern
will
often
matched
sequence
input
automated
tool
will
generally
disambiguate
choosing
first
pattern
listed
input
script
will
covering
jflex
exam
intimate
details
jflex
will
covered
expect
understand
underlying
theory
discussed
parsing
job
parser
determine
sequence
tokens
recognized
scanner
can
combined
form
syntactically
legal
input
program
output
theoretically
speaking
parse
tree
input
program
practice
boiled
version
parse
tree
flat
intermediate
representation
emitted
instead
context
free
grammar
formalism
suitable
specifying
syntax
programming
language
consists
set
terminal
symbols
correspond
tokens
can
recognized
scanner
set
nonterminal
symbols
abstractions
groupings
tokens
considered
legal
input
program
start
symbol
nonterminal
symbol
considered
abstraction
entire
input
program
set
rules
sometimes
called
productions
explain
nonterminal
symbols
can
replaced
legally
sequence
nonterminal
terminal
symbols
grammar
describes
potentially
infinite
set
syntactically
legal
input
programs
set
called
language
grammar
example
grammar
identifiers
surrounded
matched
set
parentheses
¡÷
'
'
'
'
identifier
two
ways
demonstrate
input
program
language
described
grammar
one
draw
tree
start
symbol
root
node
terminal
symbols
leaves
node
containing
nonterminal
symbol
zero
child
nodes
corresponding
symbols
right
hand
side
one
rules
another
write
derivation
derivation
corresponds
parse
tree
examples
identifier
identifier
compiler
writers
primarily
interested
two
kinds
derivations
leftmost
derivations
derivations
leftmost
nonterminal
replaced
step
rightmost
derivations
derivations
rightmost
nonterminal
replaced
step
parser's
job
discover
either
parse
tree
derivation
indicates
input
program
language
grammar
input
program
one
parse
tree
one
leftmost
rightmost
derivation
grammar
said
ambiguous
since
compiler
typically
infers
program's
meaning
structure
parse
tree
ambiguity
generally
considered
bad
thing
grammar
programming
language
one
way
resolve
ambiguity
context
free
grammar
though
techniques
help
one
technique
stratification
technique
used
establish
precedence
associativity
operators
starting
grammar
arbitrarily
nested
expressions
¡÷
identifier
can
transform
¡÷
e2
e2
e2e2
¡÷
e2
e3
e2
e3
e3e3
¡÷
identifier
often
call
grammar
classic
expression
grammar
resulting
grammar
establishes
lowest
precedence
left
associative
next
highest
precedence
left
associativeparenthesized
expressions
higher
precedence
parenthesized
top
parsing
top
parser
begins
parse
tree
whose
root
contains
start
symbol
every
step
attempts
expand
one
nonterminals
lower
fringe
tree
nonterminal
leaf
node
one
rules
expand
nonterminal
symbols
right
hand
side
selected
rule
top
parser
theoretically
expand
nonterminals
order
practice
however
top
parsing
algorithms
limited
couple
desirable
properties
like
able
parse
input
natural
order
read
scan
input
file
left
right
like
parse
input
efficiently
possible
ideally
making
right
decision
every
step
looking
input
token
order
solve
first
problem
parsing
left
right
start
algorithm
make
new
parse
tree
start
symbol
root
node
root
parse
tree
loop
node
contains
terminal
next
input
token
advance
node
next
node
lower
fringe
tree
else
backtrack
else
node
contains
nonterminal
nt
pick
rule
nt
¡÷
£]
extend
tree
using
rule
node
leftmost
symbol
£]
algorithm
works
theoretically
speaking
capable
finding
parse
tree
input
program
provided
rules
picked
nondeterministically
however
practical
matter
algorithm
terribly
inefficient
essentially
amounts
exhaustive
search
possible
parse
trees
derivations
looking
right
one
solve
second
problem
need
find
algorithm
allows
us
looking
nonterminal
nt
always
choose
right
rule
expand
order
need
support
grammar
grammar
needs
constructed
way
can
always
make
right
choice
looking
next
token
input
recursive
descent
parsing
topic
discussed
great
deal
detail
assignment
2
also
textbook
table
driven
ll
1
parsing
recursive
descent
parsing
one
form
top
ll
1
parsing
straightforward
code
hand
problem
size
code
directly
proportional
size
grammar
yet
code
follows
regular
predictable
pattern
directly
encoding
information
grammar
first
follow
sets
restructure
program
somewhat
might
able
write
code
recurring
pattern
encode
rules
expanding
nonterminals
table
table
driven
ll
1
parser
just
built
around
parsing
table
nonterminal
symbols
labeling
rows
terminal
symbols
eof
labeling
columns
intuitively
cell
table
contains
indication
rule
used
expand
next
input
symbol
rules
generally
numbered
consecutively
numbers
stored
table
precisely
table
number
rule
¡÷
£]
first
£]
rule
¡÷
£`
also
grammar
table
number
£`
rule
symbols
follow
reiterated
exactly
information
encoded
structure
code
recursive
descent
parser
information
encoded
table
code
size
affected
size
grammar
obviously
size
table
table
much
compact
code
table
algorithm
works
like
push
eof
push
start
symbol
loop
top
stack
eof
next
token
eof
accept
else
top
stack
terminal
eof
top
stack
next
token
pop
terminal
stack
consume
next
token
else
error
else
table
top
stack
next
token
rule
¡÷
£]1
£]2
£]k
pop
stack
push
£]k
£]1
else
error
naturally
want
hand
code
one
table
driven
ll
1
parsers
can
certainly
imagine
tool
take
ll
1
grammar
input
emit
table
driven
ll
1
parser
output
bottom
parsing
top
parsers
specifically
recursive
descent
table
driven
ll
1
parsers
simple
efficient
hand
implementing
may
require
number
transformations
left
factoring
left
recursion
elimination
grammar
programming
language
making
formerly
intuitive
clear
grammar
much
clunkier
one
particularly
using
tools
generate
parser
grammar
actually
part
source
code
compiler
keeping
grammar
readable
important
also
although
programming
language
constructs
can
expressed
using
ll
1
grammars
reasons
need
bottom
parsers
bottom
parser
begins
input
program
leaves
parse
tree
start
symbol
root
endeavors
every
step
combine
sequence
orphaned
nodes
parents
represent
right
hand
side
grammar
rule
together
putting
nonterminal
left
hand
side
rule
process
terminates
either
sequences
orphaned
nodes
can
combined
fashion
entire
input
program
connected
one
tree
start
symbol
root
shift
reduce
parsing
typical
bottom
parser
uses
shift
reduce
technique
shift
reduce
parser
one
built
around
parser
stack
parser
stack
consists
least
nonterminal
terminal
symbols
every
step
parser
makes
decision
whether
one
two
things
shift
push
next
token
input
stack
reduce
pop
symbols
top
stack
replace
nonterminal
symbol
whose
righthand
side
symbols
words
apply
one
grammar
rules
reverse
tricky
part
knowing
whether
shift
reduce
sequence
symbols
£]
top
stack
supposed
reduced
rule
¡÷
£]
say
£]
handle
supposed
mean
correct
move
make
reduce
rule
¡÷
£]
call
top
symbols
stack
£]
handle
mind
simple
shift
reduce
parsing
algorithm
loop
top
stack
£]
¡÷
£]
handle
pop
£]
symbols
stack
push
stack
place
action
called
reduction
else
tokens
input
push
next
token
action
called
shifting
else
stack
start
symbol
accept
else
error
problem
algorithm
course
left
important
part
determining
handle
top
stack
voodoo
magic
need
algorithm
finding
handles
can
develop
algorithm
particularly
one
can
make
decision
constant
time
step
entire
parse
will
linear
respect
total
number
shifts
total
number
reductions
lr
1
parsing
lr
1
parser
bottom
shift
reduce
parser
uses
one
mechanism
finding
handles
every
step
lr
1
parser
considered
one
finite
set
states
somewhat
like
dfa
encodes
knowledge
find
handles
two
tables
action
table
rows
labeled
parser
states
columns
labeled
terminal
symbols
eof
entry
table
indicates
one
four
actions
shift
s'
meaning
parser
shift
next
token
input
move
parser
state
s'
reduce
¡÷
£]
meaning
parser
reduce
rule
¡÷
£]
typical
lr
1
parser
rules
numbered
consecutively
uniquely
reduce
action
might
reduce
3
meaning
reduction
done
using
rule
3
grammar
accept
meaning
parser
accept
input
program
legal
error
meaning
parser
determined
error
input
program
goto
table
rows
labeled
parser
states
columns
labeled
nonterminal
symbols
entry
table
parser
state
means
parser
state
recognized
proceed
state
goto
given
tables
lr
parsing
algorithm
push
start
state
s0
loop
action
top
stack
next
token
shift
s1
push
next
token
push
si
else
action
top
stack
next
token
reduce
¡÷
£]
pop
2
£]
symbols
top
stack
push
push
goto
else
action
top
stack
next
token
accept
accept
else
error
example
algorithm
action
appears
textbook
covered
lecture
course
algorithm
works
action
goto
tables
constructed
construct
tables
use
algorithm
discussed
section
3
5
textbook
fortunately
tools
cup
given
grammar
set
associated
actions
will
generate
lr
parser
crunching
details
lr
1
construction
related
construction
lalr
reduction
associated
action
will
taken
subset
following
topics
will
covered
lecture
wednesday
february
11
topics
will
covered
midterm
whatever
detail
cover
lecture
semantic
analysis
context
sensitive
analysis
different
syntax
analysis
parsing
abstract
syntax
trees
intermediate
representation
input
program
symbol
tables
store
can
used
implement
static
scoping
type
checking
