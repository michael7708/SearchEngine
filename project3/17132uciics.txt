ics 142 winter 2004 final exam study guide 
final exam study guide 
ics
142
winter
2004
news
course
reference
schedule
lab
manual
ics
142
newsgroup
alex
ics
142
winter
2004
final
exam
study
guide
introduction
study
guide
summary
lecture
material
covered
since
midterm
final
exam
will
comprehensive
sure
understand
concepts
algorithms
covered
midterm
prepare
exam
sure
look
midterm
study
guide
summary
lecture
material
covered
midterm
intend
include
questions
final
testing
tiny
details
textbook
covered
lecture
responsible
assigned
readings
broad
ideas
important
points
readings
fair
game
exam
even
cover
lecture
included
material
study
guide
limits
topics
midterm
listed
midterm
study
guide
will
remain
limits
final
study
guide
first
jflex
cup
expect
understand
basic
principles
behind
tools
though
ask
write
either
jflex
cup
script
however
might
ask
evaluate
simple
ones
ensure
understand
work
semantic
analysis
abstract
syntax
trees
topics
explained
quite
bit
detail
already
assignment
3
write
sure
much
worthwhile
can
add
symbol
tables
much
compiler's
ability
understand
meaning
source
program
revolves
around
ability
know
meaning
identifiers
appear
manage
problem
tracking
meaning
identifiers
compilers
use
symbol
table
symbol
table
mapping
identifiers
meanings
important
information
maintained
symbol
table
early
stages
compilation
type
information
facilitates
much
static
semantic
checking
compilation
proceeds
additional
information
may
added
statically
determined
memory
addresses
offsets
activation
records
course
programming
languages
meaning
particular
identifier
may
vary
throughout
program
language's
scoping
rules
explain
meaning
names
tied
declarations
uses
elsewhere
program
almost
commonly
used
programming
languages
employ
static
scoping
rules
meaning
use
identifier
can
always
mapped
back
declaration
unambiguously
compile
time
common
kind
static
scoping
rules
enforce
kind
block
structure
program
declarations
within
one
block
say
procedure
block
statement
within
procedure
take
effect
within
block
declarations
inner
scopes
block
statements
within
block
statements
take
precedence
declarations
outer
ones
common
implementation
technique
symbol
table
case
scoped
symbol
table
scoped
symbol
table
essentially
stack
symbol
tables
lookup
scoped
symbol
table
involves
looking
name
symbol
table
stack
starting
top
proceeding
either
name
found
tables
consulted
name
found
tables
stack
error
reported
approach
lends
nicely
analysis
parsing
language
names
must
declared
use
entering
new
scope
causes
new
symbol
table
pushed
stack
exiting
scope
causing
symbol
table
popped
stack
languages
complex
scoping
rules
java
includes
lookups
throughout
inheritance
hierarchies
will
require
complex
symbol
table
implementation
interpreters
vs
compilers
scanner
parser
semantic
checker
determined
program
lexically
syntactically
static
semantically
correct
reached
fork
road
continue
intermediate
code
generation
optimization
code
generation
interested
building
compiler
can
also
continue
different
direction
instead
building
simulator
executes
program
directly
simulator
generally
called
interpreter
compilers
interpreters
share
techniques
notably
techniques
used
front
end
either
way
source
program
must
scanned
parsed
meaning
must
understood
difference
done
understood
meaning
compiler
translates
equivalent
program
target
language
interpreter
executes
program
generates
output
source
level
interpreters
using
abstract
syntax
trees
source
level
interpreter
one
interprets
source
code
somewhat
directly
rather
first
translating
intermediate
form
java
first
compiled
bytecodes
interpreted
build
source
level
interpreter
representation
source
code
will
need
available
interpreter
common
solution
problem
use
abstract
syntax
tree
traversing
evaluating
program
executes
theory
language
can
interpreted
course
interpretation
represents
tradeoff
flexibility
speed
interpreter
capable
reporting
errors
terms
original
source
code
difficult
compiled
program
interpretation
allows
programs
executed
piecemeal
testing
purposes
without
lengthy
compilation
step
interpretation
also
makes
easier
support
features
rewriting
portions
program
executing
debugger
unfortunately
interpretation
orders
magnitude
slower
execution
compiled
program
languages
tradeoff
great
others
languages
highly
dynamic
characteristics
scheme
dynamic
typing
early
versions
lisp
dynamic
typing
also
dynamic
scoping
pay
less
penalty
interpreted
relative
execution
compiled
version
since
much
housekeeping
work
maintenance
symbol
tables
tracking
types
symbols
needs
done
run
time
whether
program
interpreted
compiled
linear
intermediate
representations
result
scanning
parsing
often
creation
intermediate
representation
ir
source
program
abstract
syntax
tree
ast
one
form
ir
one
graphically
terms
object
graph
represents
source
program
typical
ast
represents
source
program
abstractions
statements
loops
directly
though
possible
build
lower
level
ir
want
ultimately
generate
assembly
code
equivalent
source
program
often
necessary
work
lower
level
ir
one
closer
level
abstraction
provided
assembly
language
typically
means
ir
will
linear
list
instructions
will
closely
resemble
assembly
language
three
benefits
linear
ir
closer
assembly
code
will
eventually
generate
simplifies
instruction
selecting
portion
code
generation
somewhat
since
linear
ir's
often
compact
graphical
ones
ast's
faster
process
importantly
opportunities
optimization
may
found
linear
ir
simply
show
ast
built
directly
source
code
since
well
designed
linear
ir
conveys
information
source
code
one
form
linear
ir
stack
machine
code
stack
machine
code
assumes
presence
operand
stack
holds
results
intermediate
calculations
operations
take
operands
stack
push
result
back
stack
example
integer
add
take
top
two
elements
stack
add
push
result
often
included
swap
operation
swaps
top
two
stack
elements
also
generally
representation
memory
used
store
values
longer
terms
advantages
simple
generate
post
order
traversal
ast
example
can
used
generate
compact
since
need
store
operands
instructions
disadvantage
good
ir
unless
targeting
stack
machine
processor
actually
uses
operand
stack
compiler
targets
conventional
processor
appropriate
representation
three
address
code
three
address
code
operations
look
roughly
like
op
op
operator
source
operands
target
operand
target
operand
may
different
source
operands
convenient
representation
easy
represent
compiler
object
four
values
stored
opcode
along
three
operands
also
matches
nicely
many
real
instruction
sets
one
notable
exception
intel
80x86
destructive
two
address
instructions
example
three
address
code
used
quarter
iloc
really
expect
memorized
iloc
instructions
familiar
enough
iloc
instructions
understand
chunk
iloc
also
understand
trade
offs
generating
different
blocks
iloc
control
flow
structures
expressions
discussed
lecture
able
apply
optimizations
similar
ones
implemented
assignment
6
perhaps
others
given
descriptions
thing
remember
iloc
instructions
follow
regular
naming
convention
makes
easy
understand
even
got
instructions
memorized
always
understanding
trumps
memorization
know
difference
regular
instructions
instructions
immediate
ai
instructions
address
immediate
ao
instructions
address
offset
know
general
instruction
groups
like
load
store
add
lshift
etc
many
cases
can
infer
meaning
based
name
prior
understanding
assembly
style
languages
prior
courses
best
place
get
description
instructions
appendix
textbook
instructions
listed
table
assignment
6
write
though
left
intend
us
use
assignment
notably
missing
assignment
example
comp
cbr
instructions
run
time
organization
compiler's
job
similar
job
programmer
programmer
maps
abstractions
problem
abstractions
source
language
example
building
java
program
manage
student
enrollment
information
classes
student
course
enrollment
might
created
compiler
maps
abstractions
provided
source
language
abstractions
provided
target
language
generally
means
taking
higher
level
abstractions
like
classes
procedures
expressions
turning
lower
level
ones
instructions
memory
usage
management
run
time
stack
number
standard
techniques
structuring
high
level
language
abstractions
assembly
level
target
programs
widely
used
execution
program
begins
operating
system
invokes
either
behalf
user
ends
program
invocation
involves
four
major
steps
os
allocates
space
program
memory
usually
means
allocating
logical
address
space
unique
program
mapping
virtual
memory
os
loads
code
program
logical
address
space
os
executes
initialization
code
initializations
global
variables
constructor
calls
global
objects
program
os
jumps
entry
point
program
main
logical
address
space
typically
organized
code
one
end
address
space
data
organized
code
implementation
typical
programming
language
data
area
split
separate
portions
global
area
global
variables
allocated
compile
time
run
time
stack
information
procedure
call
kept
form
stack
activation
records
heap
free
store
dynamically
allocated
variables
indeterminate
lifetimes
stored
qualities
programming
language
implemented
will
determine
whether
design
makes
sense
example
scheme
activations
procedures
necessarily
last
first
activation
records
must
allocated
heap
rather
stored
run
time
stack
languages
support
recursion
activation
records
can
allocated
statically
instead
perhaps
important
construct
need
manage
run
time
subprogram
problem
processors
support
high
level
concept
subprogram
directly
must
simulated
low
level
instructions
instead
activation
subprogram
complete
use
call
execution
completion
return
order
subprograms
communicate
knowing
little
possible
one
another
agreed
upon
convention
must
followed
caller
callee
convention
total
called
subprogram
linkage
lists
among
things
responsibilities
callers
callees
example
caller
must
pass
parameters
callee
previously
agreed
upon
way
callee
can
find
caller
callee
together
must
agree
will
save
processor's
state
registers
can
restored
upon
return
like
code
written
different
languages
able
communicate
one
another
possible
even
like
code
written
language
compiled
different
compilers
platform
able
communicate
reason
subprogram
linkage
often
agreed
upon
operating
system
design
time
order
separate
information
activations
one
another
information
subprogram
stored
activation
record
ar
contents
ar's
will
vary
typical
one
might
look
something
like
local
data
area
includes
local
variables
compiler
generated
temporariesmay
variable
size
since
number
temporaries
may
vary
per
execution
subprogram
depending
control
flow
caller's
ar
pointer
dynamic
link
static
link
pointer
ar
static
ancestor
return
addressreturn
value
pointerregister
save
areaparameters
language
supports
passing
variable
numbers
parameters
may
also
variable
sizein
language
typical
pass
parameters
backward
order
first
one
top
later
ones
allows
first
arguments
known
offsets
implementation
parameter
passing
modes
pass
value
pass
value
result
copy
value
actual
parameter
slot
activation
record
uses
formal
parameter
access
modify
copy
pass
reference
pass
pointer
actual
parameter
instead
actual
parameter
store
pointer
callee's
ar
whenever
formal
parameter
accessed
pointer
dereferenced
returning
values
slightly
complicated
since
returned
value
must
live
callee
dies
along
ar
one
strategy
store
return
value
pointer
callee's
ar
points
allocated
slot
caller's
ar
perhaps
local
data
area
strategy
work
caller
unaware
large
return
value
may
case
pointer
heap
allocated
return
value
returned
instead
accessing
variables
accessing
global
variables
straightforward
can
accessed
directly
statically
determined
address
local
variables
also
straightforward
access
assuming
laid
known
offset
ar
can
accessed
known
offset
assuming
register
points
current
ar
non
local
variables
trickier
assuming
block
structured
language
ar
can
maintain
static
link
points
ar
recent
activation
lexically
enclosing
subprogram
use
nonlocal
variable
can
denoted
static
distance
coordinate
explained
detail
assignment
5
write
maintaining
static
links
run
time
can
done
simple
algorithm
assuming
subprogram
level
number
indicates
depth
many
subprograms
nested
within
call
level
0
subprogram
results
callee's
static
link
pointing
null
call
level
level
1
results
callee's
static
link
pointing
caller's
ar
call
level
level
results
callee's
static
link
pointing
caller's
static
link
points
call
level
level
callee's
static
link
points
static
link
static
links
away
points
intermediate
code
generation
implementing
high
level
constructs
low
level
intermediate
instructions
compiler
many
options
strategies
will
yield
code
runs
faster
will
yield
code
uses
less
memory
less
power
many
trade
offs
must
made
selecting
implementation
strategy
high
level
construct
revolve
around
memory
hierarchy
simplistic
point
view
four
places
information
typically
stored
registers
fast
expensive
typically
many
can
usually
accessed
one
cycle
cache
nearly
fast
registers
cheaper
can
can
usually
accessed
cycles
main
memory
significantly
slower
cache
significantly
cheaper
least
tens
hundreds
times
slower
registers
disparity
getting
progressively
worse
processors
speeding
rapidly
memory
disk
millions
times
slower
registers
extremely
cheap
obvious
way
speed
program
keep
data
registers
whenever
possible
course
finite
number
registers
available
intermediate
code
sidestep
problem
using
unlimited
number
virtual
registers
counting
register
allocator
map
set
virtual
registers
set
actual
registers
toward
end
compilation
even
infinite
number
registers
data
can
stored
registers
one
name
can
used
access
variable
stored
register
unless
compiler
fully
aware
possible
names
every
context
multiple
names
can
used
procedure
boundaries
crossed
pass
reference
parameter
passing
used
value
must
stored
memory
call
loaded
afterward
fact
soon
address
variable
taken
becomes
significantly
difficult
keep
value
register
language
like
arbitrary
pointer
arithmetic
difficulty
level
even
higher
since
pointers
can
theoretically
point
anywhere
treat
value
data
type
additional
compilation
affects
whether
values
might
stored
registers
presence
multiple
threads
generating
intermediate
code
arithmetic
expression
requires
three
steps
first
generate
code
load
value
register
register
already
next
generate
code
load
value
register
already
finally
generate
add
instruction
resulting
iloc
sequence
might
look
something
like
assuming
local
variables
stored
current
activation
record
loadi
r1loadao
rarp
r1
raloadi
r2loadao
rarp
r2
rbadd
ra
rb
ra
naive
approach
generating
code
expressions
postorder
tree
traversal
keep
track
variables
stored
registers
go
along
load
values
registers
necessary
need
loaded
already
generate
code
operators
operands
loaded
main
problem
approach
may
minimize
register
usage
left
hand
side
requires
registers
order
perform
computation
right
hand
side
better
right
hand
side
computation
first
best
move
first
traverse
tree
decide
subtree
will
require
registers
generate
code
subtree
first
presence
function
calls
expressions
complicates
matters
somewhat
since
functions
may
side
effects
will
necessary
store
values
memory
call
load
afterward
possible
function
change
separate
document
titled
iloc
examples
demonstrates
explains
intermediate
code
generation
boolean
expressions
loops
discussed
lecture
optimization
optimizer
takes
input
set
intermediate
code
output
better
set
intermediate
code
one
equivalent
effect
job
better
way
faster
less
memory
usage
etc
primary
job
optimizer
understand
details
portion
intermediate
code
program
scope
optimization
portion
program
analyzed
smallest
scope
typically
one
basic
block
basic
block
straight
line
list
instructions
label
appearing
optionally
first
instruction
jump
conditional
branch
optionally
appearing
last
instruction
words
instructions
basic
block
guaranteed
execute
completely
sequence
beginning
end
first
step
many
optimizations
build
control
flow
graph
cfg
cfg
captures
control
flow
basic
blocks
individual
nodes
graph
represent
basic
blocks
edges
indicate
possible
flows
control
provided
code
assignment
6
roughly
algorithm
find
leaders
instructions
begin
basic
blocks
instruction
label
leader
follows
instruction
conditional
branch
jump
leader
leaders
found
nodes
can
built
represent
basic
block
edges
can
added
based
labels
appearing
leaders
jumps
branches
variety
optimizations
can
performed
starting
point
sure
understand
ones
implemented
assignment
6
local
optimizations
can
extended
become
superlocal
optimizations
superlocal
optimization
operates
extended
basic
block
ebb
rather
one
basic
block
ebb
set
basic
blocks
b1
b2
bn
b1
may
one
predecessor
cfg
blocks
will
unique
predecessor
ebb
words
basic
blocks
ebb
subset
nodes
cfg
tree
since
ebb
essentially
tree
basic
blocks
optimizations
constant
propagation
folding
can
easily
extended
work
ebb's
instead
basic
blocks
since
unique
predecessor
guaranteed
execute
node
ebb
optimizations
can
done
treelike
fashion
information
carried
one
node
another
along
path
tree
complications
optimization
typically
arrive
join
points
cfg
nodes
multiple
predecessors
superlocal
optimizations
deal
nodes
though
predecessors
discarding
known
information
beginning
process
instruction
scheduling
topic
will
covered
exam
