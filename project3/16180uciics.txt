selection order statistics 
order statistics selection 
ics
161
design
analysis
algorithms
lecture
notes
january
25
1996
selection
order
statistics
statistics
refers
methods
combining
large
amount
data
scores
whole
class
homework
single
number
small
set
numbers
give
overall
flavor
data
phrase
order
statistics
refers
statistical
methods
depend
ordering
data
numerical
values
instance
average
data
easy
compute
important
estimate
central
value
order
statistic
mode
commonly
occurring
value
also
depend
ordering
although
efficient
methods
computing
comparison
based
model
involve
sorting
algorithms
commonly
used
order
statistic
median
value
middle
position
sorted
order
values
can
get
median
easily
log
time
via
sorting
maybe
possible
better
see
answer
yes
will
solve
median
recursively
sometimes
especially
relation
recursive
algorithms
easier
solve
general
problem
one
started
making
problem
difficult
paradoxically
makes
easier
solve
true
problem
general
may
easier
us
find
recursive
subproblems
help
lead
us
solution
general
problem
solve
selection
given
list
items
number
1
find
item
kth
sorted
list
median
special
case
2
see
two
algorithms
general
problem
randomized
one
based
quicksort
quickselect
deterministic
one
randomized
one
easier
understand
better
practice
first
get
warm
cases
selection
much
medians
far
2
second
best
search
1
selection
problem
trivial
just
select
minimum
element
usual
maintain
value
minimum
seen
far
compare
successive
value
updating
something
smaller
seen
min
1
2
return
want
select
second
best
one
possibility
follow
general
strategy
modify
min
keep
two
values
best
second
best
seen
far
need
compare
new
value
second
best
tell
whether
top
two
discover
new
value
one
top
two
far
need
tell
whether
best
second
best
second
1
2
switch
3
switch
return
although
algorithm
pretty
easy
come
interesting
behavior
shows
try
analyze
worst
case
list
may
sorted
decreasing
order
2
iterations
loop
performs
2
comparisons
total
2n
3
comparisons
average
case
assuming
permutation
equally
likely
first
comparison
iteration
still
always
happens
second
happens
one
two
smallest
values
among
first
first
values
equally
likely
one
two
true
probability
2
total
expected
number
times
make
second
comparison
sum
2
2
ln
1
3
ln
natural
logarithm
sum
1
1
known
harmonic
series
ln
1
can
proved
using
calculus
comparing
sum
similar
integral
therefore
total
expected
number
comparisons
overall
log
small
increase
1
comparisons
needed
find
minimum
gives
us
hope
can
perform
selection
faster
sorting
heapselect
saw
randomized
algorithm
log
comparison
expected
can
get
performance
unrandomized
algorithm
think
basketball
tournaments
involving
teams
form
complete
binary
tree
leaves
internal
node
represents
elimination
game
bottom
level
2
games
2
winners
go
game
next
level
tree
assuming
better
team
always
wins
game
best
team
always
wins
games
can
found
winner
last
game
easily
expressed
pseudo
code
far
just
complicated
algorithm
finding
minimum
maximum
practical
advantages
namely
parallel
many
games
can
played
fair
contrast
used
algorithm
min
teams
placed
earlier
play
many
games
big
disadvantage
now
tree
second
best
team
team
always
beat
everyone
except
eventual
winner
must
lost
since
overall
winner
never
loses
must
lost
eventual
winner
therefore
one
log
teams
played
eventual
winner
can
run
another
tournament
algorithm
among
values
express
algorithm
finding
second
best
uses
ceil
log
comparisons
even
better
average
case
algorithm
think
elimination
tournament
described
similar
ways
binary
heap
process
finding
second
best
running
teams
played
winner
similar
process
removing
minimum
heap
can
therefore
use
heaps
extend
idea
small
values
heapselect
heap
heapify
1
remove
min
return
min
time
obviously
log
log
result
interesting
still
help
median
finding
quick
select
solve
median
problem
go
back
idea
using
sorting
algorithm
finding
middle
element
sorted
list
specifically
look
quicksort
quicksort
pick
partition
l1
l2
l3
quicksort
l1
quicksort
l3
concatenate
l1
l2
l3
selection
algorithm
called
quicksort
explicitly
looking
middle
element
instead
put
look
middle
element
line
quicksort
pseudocode
select
pick
partition
l1
l2
l3
quicksort
l1
quicksort
l3
concatenate
l1
l2
l3
return
kth
element
concatenation
recursive
algorithm
since
call
although
call
quicksort
recursive
just
like
quicksort
takes
time
log
notice
less
length
l1
will
always
return
object
l1
matter
whether
call
quicksort
l3
order
elements
l3
make
difference
similarly
greater
combined
lengths
l1
l2
will
always
return
object
l3
matter
whether
call
quicksort
l1
either
case
can
save
time
making
one
two
recursive
calls
find
element
returned
l2
can
just
immediately
return
without
making
either
recursive
call
can
also
save
little
time
much
concatenation
instead
directly
looking
right
place
l1
l2
l3
select
pick
partition
l1
l2
l3
length
l1
quicksort
l1
return
kth
element
l1
else
length
l1
length
l2
quicksort
l3
return
length
l1
length
l2
element
l3
else
return
far
improvement
makes
fewer
calls
quicksort
still
log
algorithm
one
final
observation
though
code
inside
statement
sorts
list
returns
position
words
solves
exactly
sort
selection
problem
started
make
improvements
one
two
recursive
calls
two
remaining
calls
quicksort
simply
replacing
pieces
code
recursive
call
selection
routine
quickselect
pick
partition
l1
l2
l3
length
l1
return
quickselect
l1
else
length
l1
length
l2
return
quickselect
l3
length
l1
length
l2
else
return
analysis
quickselect
quickselect
always
makes
recursive
call
one
smaller
problem
pretended
always
problem
half
size
get
recurrence
2
course
worst
case
recursive
call
can
problem
one
fewer
element
l3
empty
l2
one
element
instead
give
us
recurrence
1
2
worst
case
algorithm
bad
instead
want
analyze
average
case
much
better
perform
average
case
analysis
rigorously
form
randomized
recurrence
two
parameters
worst
case
turns
2
keep
things
simple
just
write
one
variable
recurrence
assuming
worst
case
assumption
makes
analysis
sloppier
gives
bound
know
will
least
worse
might
actually
better
now
always
eliminate
l2
min
l1
l3
objects
list
step
except
return
case
algorithm
terminates
roughly
min
equally
likely
number
1
2
recursive
call
quickselect
equally
likely
involve
list
size
2
different
2
make
smaller
sizes
likely
larger
sizes
less
likely
can
used
prove
2
really
worst
case
usual
expected
case
analysis
get
recurrence
involving
sum
possible
choices
probability
making
choice
multiplied
time
take
made
choice
measure
things
comparisons
recurrence
1
sum
2
2
analyze
something
like
know
come
know
constant
factor
knew
correct
constant
factor
able
prove
inductively
cn
method
simply
plug
ci
left
side
grind
sums
verify
result
cn
one
also
prove
base
case
induction
course
note
sort
proof
needs
explicit
constant
enough
plug
left
side
verify
result
right
side
exercise
1
inductive
proof
show
induction
hypothesis
hint
constant
factor
hidden
notation
needs
truly
constant
something
can
grow
time
induct
knew
perform
explicit
induction
proof
cn
even
though
know
can
still
work
sums
get
something
form
tells
us
explicit
induction
proof
works
working
sums
unknown
value
get
information
helps
us
determine
try
strategy
quickselect
1
sum
2
2
1
sum
2
ci
2
2c
1
sum
2
2c
2
1
1
sum
sum
1
1
1
2c
2
2
2
8
1
3c
4
1
induction
works
large
enough
base
case
swamp
1
term
whenever
greater
4
quickselect
uses
roughly
4n
comparisons
expectation
quicker
selection
floyd
rivest
noticed
choosing
pivot
point
carefully
one
can
get
much
better
algorithm
just
describe
sketchy
analysis
book
test
something
like
using
want
medians
large
data
sets
want
read
good
recent
reference
average
case
selection
walter
cunto
ian
munro
journal
acm
vol
36
2
april
1989
pages
270
279
sampleselect
given
choose
parameters
appropriately
pick
random
subset
l'
elements
sampleselect
l'
partition
l1
l2
l3
length
l1
return
sampleselect
l1
else
length
l1
length
l2
return
sampleselect
l3
length
l1
length
l2
else
return
basic
idea
closer
kth
position
items
eliminate
final
recursive
call
taking
median
sample
instead
just
choosing
randomly
likely
get
something
closer
kth
position
choose
typically
small
fraction
time
used
first
recursive
call
small
pick
exact
value
analysis
choose
appropriately
want
likely
median
l'
close
median
way
much
possible
gets
removed
recursive
calls
specifically
small
want
median
l'
slightly
greater
median
stuff
gets
removed
likely
larger
side
conversely
large
want
little
small
fudge
fudge
positive
small
negative
large
general
right
value
fudge
sqrt
log
reasons
take
complicated
probability
theory
explain
result
top
level
call
probably
eliminated
either
items
larger
kth
position
items
smaller
recursive
calls
likely
near
1
near
within
log
sqrt
since
adjacent
samples
l'
likely
separated
roughly
positions
second
level
recursion
probably
eliminated
items
side
kth
position
likely
many
fewer
items
left
log
sqrt
precise
bulk
time
happens
first
two
calls
first
one
comparisons
second
likely
min
putting
recurrence
get
min
2t
log
sqrt
total
time
high
probability
also
can
show
just
use
quickselect
recursive
calls
instead
analyzing
recurrence
recurrence
mean
figuring
high
probability
starts
meaning
iterate
recurrence
several
times
just
replace
formula
min
log
sqrt
still
free
parameter
finish
description
algorithm
analysis
need
choose
make
large
term
will
dominate
formula
make
small
term
will
dominate
make
just
right
make
terms
roughly
equal
log
sqrt
3
2
log
log
2
3
result
algorithm
uses
min
log
2
3
comparisons
high
probability
expectation
turns
good
possible
randomized
algorithm
remains
open
problem
exactly
many
comparisons
needed
without
randomization
theoretical
significance
since
practice
randomization
good
current
best
algorithms
use
roughly
2
95
comparisons
quite
complicated
next
time
see
simpler
still
complicated
method
comparisons
ics
161
dept
information
computer
science
uc
irvine
last
update
09
jul
2003
16
47
45
pdt
