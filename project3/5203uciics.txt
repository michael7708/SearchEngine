untitled document 
ics 280 learning graphical models 
learning
graphical
models
spring
2006
ics
274b
instructor
max
welling
code
typ
sec
unt
instructor
time
place
36745
lec
4
welling
tuth
2
00
3
20p
cs
213
prerequisites
ics
274a
probabilistic
learning
theory
algorithms
consent
instructor
goals
many
modern
approaches
probabilistic
modeling
real
world
data
sets
can
formulated
unifying
framework
graphical
models
graphical
models
provide
common
language
think
communicate
probabilistic
models
makes
explicit
underlying
assumptions
moreover
provides
appropriate
structure
computations
necessary
inference
learning
models
primary
goal
course
familiarize
student
concepts
graphical
models
particular
learning
models
data
student
successfully
completed
course
able
understand
wide
variety
well
known
models
terms
unifying
framework
feel
comfortable
using
design
new
models
course
will
contain
1
formal
mathematical
sections
necessary
development
theory
2
examples
probabilistic
models
re
formulated
language
graphical
models
3
examples
successful
applications
real
data
secondary
goal
class
give
students
hands
experience
solving
real
world
problems
purpose
negotiated
deal
scitech
san
diego
based
company
improve
naive
bayes
classifier
particular
classification
problem
prediction
activity
levels
chemical
compounds
data
see
will
provide
300
bonus
student
will
come
present
work
addition
provided
goals
met
one
student
can
implement
algorithm
software
package
summer
intern
homework
slides
serve
give
impression
done
last
time
expect
will
significantly
deviate
also
homework
will
updated
go
book
book
chapters
can
found
password
protected
directory
week
1
roc
read
sections
2
1
2
2
2
3
chapter
2
david
mackay's
book
read
chapter
2
5
plates
13
mike
jordan's
book
read
classnotes
excercises
hw1
week
2
read
chapter
6
7
mike
jordan's
book
excercises
hw2
relevant
ones
topics
treated
class
project
1
due
may
4
week
3
read
chapter
9
19
20
mike
jordan's
book
excercises
hw3
excercises
hw4
relevant
ones
topics
treated
class
point
homework
optional
instructive
stuff
line
updated
week
4
read
chapter
8
mike
jordan's
book
topics
treated
class
week
5
overview
9
read
chapter
10
11
mike
jordan's
book
topics
treated
class
read
classnotes
week
6
1
excercises
hw6
due
th
feb
26
week
7
classnotes
read
chapter
14
classnotes
work
projects
week
8
classnotes
read
chapter
1
classnotes
topics
explained
class
required
reading
material
work
projects
week
9
slides
16
slides
17
classnotes
hmm
classnotes
kf
read
chapters
12
15
classnotes
tutorial
topics
explained
class
required
reading
material
work
projects
week
10
presentation
projects
review
current
trends
machine
learning
week
11
final
exam
matlab
demos
week
1
demo
bayes
demo
map
demo
ml
plotgauss1d
plotgauss2d
ginput2
week
2
demo
linreg
demo
logreg
week5
demo
em
week6
mog
demo
plotgauss
color
randmean
randcovariance
kmeans
dist2
randvec
gaussian
week7
demo
pca
fa
week8
demo
gibbs
demo
mcmc
week9
demo
hmm
demo
kf
demo
kf2
scitech
dataset
training
labels
0
inactive
compound
1
medium
active
compound
2
active
compound
continuous
attributes
2
continuous
attributes
alogp
molecular
weight
discrete
attributes
3
discrete
attributes
num
acceptors
num
donors
num
rotatablebonds
binary
finger
print
sparse
binary
matrix
1
code
presence
certain
substructures
using
available
attributes
wish
predict
activity
level
compound
background
reading
paper1
paper2
scitech
powerpoint
slides
syllabus
course
will
primarily
lecture
based
homework
exams
homework
will
revolve
around
implementation
various
classification
algorithms
scitech
dataset
provided
required
use
matlab
coding
work
following
rough
syllabus
subject
change
1
review
statistical
concepts
random
variables
probability
distributions
probability
densities
multivariate
gaussian
distribution
marginal
conditional
independence
bayes'
rule
estimation
maximum
likelihood
map
estimates
bayesian
inference
bias
variance
tradeoff
model
selection
averaging
fitting
2
graphical
models
markov
random
fields
undirected
graphical
models
bayesian
networks
directed
acyclic
graphical
models
semantics
graphical
models
independence
assumptions
markov
properties
markov
blanket
separability
factor
graphs
chain
graphs
plates
3
hidden
variables
exact
inference
observed
hidden
random
variables
bayes'
ball
algorithm
exact
inference
junction
tree
propagation
cut
set
conditioning
4
learning
graphical
models
expectation
maximization
algorithm
free
energy
minimization
iterative
conditional
modes
iterative
scaling
5
unsupervised
learning
directed
graphical
models
mixture
gaussians
means
principal
components
analysis
probabilistic
principal
components
analysis
factor
analysis
independent
components
analysis
latent
dirichlet
allocation
6
unsupervised
learning
undirected
graphical
models
boltzmann
machines
products
experts
additive
random
field
models
examples
vision
text
7
supervised
learning
directed
undirected
graphical
models
naive
bayes
graphical
model
logistic
regression
linear
regression
conditional
mixture
models
mixtures
experts
conditional
random
fields
8
graphical
models
time
series
state
space
models
autoregressive
models
hidden
markov
models
baum
welch
viterbi
algorithm
kalman
filter
smoother
dynamic
bayes
nets
examples
speech
biological
sequence
data
9
approximate
inference
mean
field
methods
structured
variational
inference
loopy
belief
propagation
region
graphs
generalized
belief
propagation
sampling
rejection
sampling
importance
sampling
particle
filters
markov
chain
monte
carlo
sampling
gibbs
sampling
hybrid
monte
carlo
sampling
10
bayesian
learning
structure
learning
graphical
models
conjugate
priors
fully
observed
bayes'
nets
variational
bayes
algorithm
sampling
posterior
laplace
approximation
chow
liu's
algorithm
trees
structure
learning
fully
observed
bayes'
nets
structure
learning
presence
hidden
variables
structural
em
grading
criteria
grading
will
based
combination
weekly
homework
project
40
grade
midterm
exam
30
final
exam
30
textbook
textbook
will
used
course
published
yet
copies
will
distributed
class
1
jordan
introduction
graphical
models
optional
side
readings
2
mackay
information
theory
inference
learning
algorithms
3
jordan
learning
graphical
models
4
frey
graphical
models
machine
learning
digital
communication
5
pearl
probabilistic
reasoning
intelligent
systems
6
duda
hart
stork
pattern
classification
7
bishop
neural
networks
pattern
recognition
8
hastie
tibshirani
friedman
elements
statistical
learning
9
ripley
pattern
recognition
neural
networks
