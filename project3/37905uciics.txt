ics 180 april 15 1997 
neural nets genetic algorithms methods automatically learning evaluation functio 
ics
180a
spring
1997
strategy
board
game
programming
lecture
notes
april
15
1997
tuning
evaluation
function
last
time
talked
different
types
functions
evaluate
features
position
combine
evaluation
function
adding
values
many
functions
numbers
come
othello
might
say
four
functions
pos
material
pieces
opponent
pieces
pos
corners
control
opponent
controls
pos
mobility
moves
available
want
form
evaluation
function
combining
probably
terms
eval
instance
might
try
eval
1
10
1
numbers
come
combination
numbers
gives
best
performance
various
methods
finding
numbers
hand
normalize
since
care
ordering
evaluations
usually
actual
evaluation
values
can
multiply
everything
constant
without
changing
results
means
can
choose
particular
value
say
material
value
pawn
force
one
values
expressed
terms
many
pawns
value
worth
net
effect
one
fewer
parameter
needs
setting
deduce
constraints
sometimes
possible
choose
parameters
considering
want
machine
certain
types
positions
instance
chess
usually
bad
trade
rook
bishop
knight
even
also
end
winning
single
pawn
good
win
two
pawns
material
values
satisfy
prevent
single
pawn
trade
2p
encourage
double
pawn
trade
inequalities
smaller
set
weights
satisfy
can
sometimes
help
get
reasonable
starting
approximation
evaluation
weights
probably
still
need
adjustment
afterwards
hand
tweaking
commonly
used
simply
play
program
enough
times
get
idea
strengths
weaknesses
guess
parameters
improve
best
pick
new
values
parameters
produces
reasonable
answer
quickly
requires
understand
game
well
enough
play
reasonable
games
computer
analyze
wrong
best
computer
stupid
intelligent
without
human
intervention
much
review
171
students
who've
taken
171
already
probably
time
much
hand
tweaking
hill
climbing
like
hand
tweaking
make
small
change
weights
test
performance
change
keep
change
performance
improves
repeat
many
times
tends
slow
get
stuck
local
optima
eval
weights
bad
change
makes
even
worse
simulated
annealing
like
hill
climbing
makes
small
changes
eval
keeps
changes
improve
performance
change
improve
performance
sometimes
randomly
certain
probability
accepts
change
anyway
attempt
escape
local
optima
need
specify
probabilities
start
high
gradually
become
lower
even
slower
hill
climbing
eventually
can
get
good
values
genetic
algorithms
hill
climbing
simulated
annealing
maintain
one
good
set
weights
change
gradually
instead
genetic
algorithms
maintain
collection
several
different
good
sets
weights
add
new
sets
collection
combining
pairs
existing
ones
take
weights
one
another
little
mutation
well
keep
size
collection
killing
sets
weights
bad
performance
neural
networks
really
type
evaluation
function
method
choosing
weights
neuron
function
form
threshhold
weighted
sum
inputs
one
can
form
networks
neurons
first
layer
take
inputs
basic
features
position
individual
bits
bitboard
representation
successive
layers
take
inputs
neurons
previous
layer
one
layer
network
one
input
neurons
first
order
evaluation
functions
talked
last
time
straightforward
build
much
complicated
neural
networks
hard
use
thing
evaluation
function
just
recompute
outputs
neurons
changed
inputs
question
set
weights
along
methods
developed
specifically
neural
networks
temporal
difference
learning
basic
idea
decide
network
makes
bad
decision
determine
weight
separately
whether
changing
lead
better
decision
lot
like
hill
climbing
one
advantage
neural
nets
need
even
less
human
intelligence
automatic
learning
methods
even
really
need
understand
game
well
enough
program
decent
evaluation
function
however
time
available
us
weeks
get
good
results
faster
intelligent
leaving
less
work
machines
methods
require
method
automatically
evaluating
performance
program
can
run
program
large
suite
test
positions
say
taken
high
quality
human
games
see
gets
right
answers
can
play
program
known
opponent
say
another
program
see
often
wins
can
play
program
versions
hill
climbing
modified
program
can
play
unmodified
one
disadvantage
unless
randomness
system
programs
will
play
exactly
time
get
see
results
one
game
may
representative
overall
play
one
possible
way
around
start
playing
several
different
games
positions
taken
test
suite
can
compare
results
evaluation
function
results
combining
evaluation
search
eval
good
similar
vice
versa
true
actually
done
automatically
learning
evaluation
weights
good
source
jay
scott's
machine
learning
games
web
page
lists
two
experiments
think
particularly
interesting
john
stanback
well
known
commercial
chess
programmer
tried
using
genetic
algorithm
set
weights
evaluation
function
program
zarkov
ran
2000
3000
games
think
way
got
material
values
ok
still
worse
hand
tuned
values
think
lesson
genetic
algorithms
work
need
either
lot
generations
good
initial
set
weights
risto
miikkulainen
genetic
algorithms
researcher
texas
gave
talk
last
year
experiments
done
othello
used
genetic
algorithm
tune
weights
neural
net
evaluation
function
performance
evaluation
net
done
play
fixed
opponent
fixed
opponent
played
randomly
neural
net
learned
evaluation
form
piece
square
tables
pieces
corners
good
pieces
next
corners
bad
etc
won
time
stopped
learning
opponent
combining
piece
square
tables
short
search
eventually
weeks
computer
time
learned
better
mobility
based
strategy
opponent
already
sophisticated
mobility
based
program
lost
time
never
started
learning
think
lesson
play
programs
similar
strength
instance
compare
different
evaluations
genetic
algorithm's
current
collection
playing
alternatively
play
several
fixed
opponents
different
strengths
david
eppstein
dept
information
computer
science
uc
irvine
wednesday
28
nov
2001
20
59
54
pst
