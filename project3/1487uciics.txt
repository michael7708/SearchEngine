
summary netgames 03 papers 
modeling
player
session
times
online
games
chang
feng
network
traces
popular
cs
server
week
april
2002
16k
user
sessions
recorded
99
players
play
less
2
hours
play
session
follows
weibull
distribution
0
5
£f
20
shape
similar
1
exp
play
sessions
10
100
minutes
chance
disconnecting
ie
failure
rate
remains
constant
2
5
play
sessions
shorter
10
minutes
10
chance
disconnecting
possible
reasons
connection
problems
kicked
leave
server
rules
friendly
fire
allowed
kicked
kill
team
mates
often
fair
message
exchange
framework
distributed
multi
player
games
guo
et
al
assumptions
independent
clocks
synchronization
mechanism
players
react
server
updates
updates
consist
creation
removal
object
object
position
updates
users
reaction
time
act
response
server
update
messages
ignore
latency
induced
network
compare
user
reaction
times
determine
update
actually
run
world
state
fair
ordering
service
dynamically
enforces
sufficient
waiting
period
action
message
guarantee
fair
processing
action
messages
practically
waiting
period
bounded
ensure
relative
level
interactivity
proxies
game
agnostic
located
near
players
ie
low
latency
player
proxy
proxy
receives
action
message
user
forwards
action
message
message
identification
number
deliver
messages
order
reaction
time
game
server
causality
media
synchronization
control
networked
multimedia
games
centralized
versus
distributed
ishibashi
et
al
causality
control
preserves
order
events
game
data
keyboard
inputs
need
causality
voice
video
media
synchronization
control
intra
stream
temporal
relation
mu
voice
video
packets
inter
stream
timing
among
multiple
streams
group
timing
among
multiple
end
points
ensure
fairness
synchronization
controls
compare
p2p
architectures
terms
success
4
previously
mentioned
control
schemes
voice
video
need
go
server
sent
p2p
mode
scenarios
adaptive
£_
causality
control
used
game
data
scenarios
recipient
considers
packet
still
valid
£_
50
ms
generation
timestamp
means
latency
automatically
increases
£_
ms
packets
adaptive
means
value
£_
changes
based
network
load
smaller
£_
game
interactive
large
£_
less
packets
discarded
late
misordered
unfairness
appears
terminals
different
£_
hence
need
group
sync
control
piggy
back
mu
succeeding
4
mus
recover
lost
udp
packets
experiment
two
terminals
p2p
scenarios
two
terminal
1
connected
overloaded
hub
delay
jitter
terminal
2
connected
hub
connections
10
mbps
ethernet
server
connected
t2's
hub
additional
delay
100
ms
introduced
two
terminals
data
link
simulator
t1's
hub
t2's
hub
game
mus
20
bytes
sent
10
times
per
second
voice
mus
400
bytes
sent
20
times
per
sec
video
mus
5kb
sent
20
times
per
sec
hence
load
network
comes
voice
audio
game
data
experiment
ran
2
minutes
heavy
loads
8mbps
better
causality
worse
consistency
fairness
interactivity
bandwidth
requirement
state
consistency
three
multiplayer
game
architectures
pellegrino
dovrolis
compare
p2p
pp
ca
p2p
central
authority
arbiter
receiving
moves
players
notifying
detects
inconsistencies
tu
duration
client
loop
lu
size
update
messages
cs
client
upstream
lu
tu
client
downstream
lu
tu
server
downstream
lu
tu
server
upstream
lu
tu
p2p
client
upstream
client
downstream
1
lu
tu
pp
ca
client
upstream
lu
tu
client
downstream
1
lu
tu
lu
tu
ratio
inconsistencies
corrected
arbiter
downstream
lu
tu
arbiter
upstream
lu
tu
access
network
delay
networked
games
jehaes
et
al
look
delays
introduced
access
networks
aka
last
mile
links
back
bone
goal
dimension
network
reach
minimum
delay
possible
network
delay
can
caused
propagation
mostly
case
back
bones
though
5
km
serialization
putting
bits
packet
link
packet
processing
route
dns
lookups
error
correction
queuing
packets
treated
differs
packet
packet
hence
jitter
defined
95
percentile
rtt
5
percentile
rtt
minimal
rtt
packet
processing
delay
packet
size
reff
effective
link
rate
tque
total
queuing
delay
downstream
results
jitter
experiment
5
different
values
throw
100
pings
get
rtt
jitter
tque
100
pings
obtain
reff
taking
inverse
best
fitting
trend
line
5
points
average
rtt
obtain
min
rtt
intercept
trend
line
5
points
top
1
rtt
qos
improves
rtt
separating
game
traffic
traffics
service
platform
line
games
saha
et
al
middleware
transparent
possible
game
developer
middleware
sits
top
existing
grid
infrastructure
ibm
called
globus
globus
decides
spawn
new
game
server
instance
based
current
resources
demands
player
services
charge
authentication
account
handling
chat
rooms
locating
games
selecting
server
taking
account
player
preferences
team
region
actually
playing
game
publisher
services
deal
software
deployment
updates
billing
monitoring
server
performance
service
level
agreement
5
players
suffer
100ms
delay
system
services
include
resource
management
directory
services
services
accessed
grid
provider
clients
submit
jobs
using
format
containing
executable
arguments
resource
requirements
jobs
can
require
spawning
instances
different
grid
locations
different
regions
various
services
resource
informations
information
providers
cpu
os
ram
connectivity
indexed
ldap
game
specific
services
tracking
player
stats
server
load
also
added
top
existing
services
