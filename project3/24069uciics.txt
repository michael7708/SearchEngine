data compression section 5 
other adaptive methods 
data
compression
5
adaptive
methods
two
adaptive
data
compression
methods
algorithm
bstw
lempel
ziv
coding
discussed
section
like
adaptive
huffman
coding
techniques
methods
require
first
pass
analyze
characteristics
source
thus
provide
coding
transmission
real
time
however
schemes
diverge
fundamental
huffman
coding
approach
greater
degree
methods
discussed
section
4
algorithm
bstw
defined
word
scheme
attempts
exploit
locality
lempel
ziv
coding
free
parse
method
words
source
alphabet
defined
dynamically
encoding
performed
lempel
ziv
coding
basis
unix
utility
compress
algorithm
bstw
variable
variable
scheme
lempel
ziv
coding
variable
block
5
1
lempel
ziv
codes
lempel
ziv
coding
represents
departure
classic
view
code
mapping
fixed
set
source
messages
letters
symbols
words
fixed
set
codewords
coin
term
free
parse
characterize
type
code
set
source
messages
codewords
mapped
defined
algorithm
executes
adaptive
methods
create
set
codewords
dynamically
defined
word
schemes
fixed
set
source
messages
defined
context
eg
text
file
processing
source
messages
might
single
letters
pascal
source
file
processing
source
messages
might
tokens
lempel
ziv
coding
defines
set
source
messages
parses
ensemble
lempel
ziv
algorithm
consists
rule
parsing
strings
symbols
finite
alphabet
substrings
words
whose
lengths
exceed
prescribed
integer
1
coding
scheme
maps
substrings
sequentially
uniquely
decipherable
codewords
fixed
length
2
ziv
lempel
1977
strings
selected
nearly
equal
probability
occurrence
result
frequently
occurring
symbols
grouped
longer
strings
infrequent
symbols
appear
short
strings
strategy
effective
exploiting
redundancy
due
symbol
frequency
character
repetition
high
usage
patterns
figure
5
1
shows
small
lempel
ziv
code
table
low
frequency
letters
assigned
individually
fixed
length
codewords
case
12
bit
binary
numbers
represented
base
ten
readability
frequently
occurring
symbols
blank
represented
zero
appear
long
strings
effective
compression
achieved
long
string
replaced
single
12
bit
code
symbol
string
code
1
2
3
th
4
5
6
ad
7
8
9
10
0
11
00
12
000
13
0000
14
15
4095
figure
5
1
lempel
ziv
code
table
lempel
ziv
method
incremental
parsing
strategy
coding
process
interlaced
learning
process
varying
source
characteristics
ziv
lempel
1977
figure
5
1
run
length
encoding
zeros
blanks
learned
lempel
ziv
algorithm
parses
source
ensemble
collection
segments
gradually
increasing
length
encoding
step
longest
prefix
remaining
source
ensemble
matches
existing
table
entry
alpha
parsed
along
character
following
prefix
ensemble
new
source
message
alpha
added
code
table
new
table
entry
coded
codeword
existing
table
entry
appended
character
example
ensemble
010100010
parsed
0
1
01
00
010
coded
0
0
0
1
1
1
1
0
3
0
table
built
message
ensemble
example
shown
figure
5
2
coded
ensemble
form
0
1
space
0
3
0
space
0
6
6
space
0
9
10
space
0
12
13
5
0
16
17
0
19
20
20
string
table
represented
efficient
manner
figure
5
1
string
represented
prefix
codeword
followed
extension
character
table
entries
fixed
length
lempel
ziv
strategy
simple
greedy
simply
parses
longest
recognized
string
time
rather
searching
best
way
parse
ensemble
messagecodeworda11space2b33b4space5c66c76space8d99d1010space11
messagecodeworde1212e1313e145f15f1616f1717f18g1919g2020g21
figure
5
2
lempel
ziv
table
message
ensemble
example
code
length
173
lempel
ziv
method
specifies
fixed
length
codewords
size
table
maximum
source
message
length
determined
length
codewords
clear
definition
algorithm
lempel
ziv
codes
tend
quite
inefficient
initial
portion
message
ensemble
example
even
assume
3
bit
codewords
characters
space
5
bit
codewords
table
indices
lempel
ziv
algorithm
transmits
173
bits
ensemble
example
compares
poorly
methods
discussed
survey
ensemble
must
sufficiently
long
procedure
build
enough
symbol
frequency
experience
achieve
good
compression
full
ensemble
codeword
length
sufficiently
large
lempel
ziv
codes
may
also
rise
slowly
reasonable
efficiency
maintain
good
performance
briefly
fail
make
gains
table
full
messages
can
longer
added
ensemble's
characteristics
vary
time
method
may
stuck
behavior
learned
may
unable
continue
adapt
lempel
ziv
coding
asymptotically
optimal
meaning
redundancy
approaches
zero
length
source
ensemble
tends
infinity
however
particular
finite
sequences
compression
achieved
may
far
optimal
storer
szymanski
1982
method
begins
source
symbol
coded
individually
case
6
8
bit
source
symbols
12
bit
codewords
method
yields
much
50
expansion
initial
encoding
initial
inefficiency
can
mitigated
somewhat
initializing
string
table
contain
source
characters
implementation
issues
particularly
important
lempel
ziv
methods
straightforward
implementation
takes
2
time
process
string
symbols
encoding
operation
existing
table
must
scanned
longest
message
occurring
prefix
remaining
ensemble
rodeh
et
al
address
issue
computational
complexity
defining
linear
implementation
lempel
ziv
coding
based
suffix
trees
rodeh
et
al
1981
rodeh
et
al
scheme
asymptotically
optimal
input
must
long
order
allow
efficient
compression
memory
requirements
scheme
large
length
source
ensemble
also
mentioned
method
rodeh
et
al
constructs
variable
variable
code
pair
coded
using
representation
integers
elias
codes
letter
can
always
coded
kth
member
source
alphabet
major
implementation
consideration
involves
way
string
table
stored
accessed
welch
suggests
table
indexed
codewords
integers
1
2
maximum
codeword
length
table
entries
fixed
length
codeword
extension
character
pairs
welch
1984
hashing
proposed
assist
encoding
decoding
becomes
recursive
operation
codeword
yields
final
character
substring
another
codeword
decoder
must
continue
consult
table
retrieved
codeword
0
unfortunately
strategy
peels
extension
characters
reverse
order
type
stack
operation
must
used
reorder
source
storer
szymanski
present
general
model
data
compression
encompasses
lempel
ziv
coding
storer
szymanski
1982
broad
theoretical
work
compares
classes
macro
schemes
macro
schemes
include
methods
factor
duplicate
occurrences
data
replace
references
either
source
ensemble
code
table
also
contribute
linear
time
lempel
ziv
like
algorithm
better
performance
standard
lempel
ziv
method
rissanen
extends
lempel
ziv
incremental
parsing
approach
rissanen
1983
abandoning
requirement
substrings
partition
ensemble
rissanen
method
gathers
contexts
symbol
string
occurs
contexts
substrings
previously
encoded
string
lempel
ziv
varying
size
general
overlapping
rissanen
method
hinges
upon
identification
design
parameter
capturing
concept
relevant
contexts
problem
finding
best
parameter
undecidable
rissanen
suggests
estimating
parameter
experimentally
mentioned
earlier
lempel
ziv
coding
basis
unix
utility
compress
one
methods
commonly
used
file
archival
programs
archival
system
pkarc
uses
welch's
implementation
compress
compression
provided
compress
generally
much
better
achieved
compact
unix
utility
based
algorithm
fgk
takes
less
time
compute
unix
1984
typical
compression
values
attained
compress
range
50
60
5
2
algorithm
bstw
recent
algorithms
surveyed
due
bentley
sleator
tarjan
wei
bentley
et
al
1986
method
algorithm
bstw
possesses
advantage
requires
one
pass
data
transmitted
yet
performance
compares
well
static
two
pass
method
along
dimension
number
bits
per
word
transmitted
number
bits
never
much
larger
number
bits
transmitted
static
huffman
coding
fact
usually
quite
close
can
significantly
better
algorithm
bstw
incorporates
additional
benefit
taking
advantage
locality
reference
tendency
words
occur
frequently
short
periods
time
fall
long
periods
disuse
algorithm
uses
self
organizing
list
auxiliary
data
structure
employs
shorter
encodings
words
near
front
list
many
strategies
maintaining
self
organizing
lists
see
hester
hirschberg
1985
algorithm
bstw
uses
move
front
simple
example
serves
outline
method
algorithm
bstw
adaptive
schemes
sender
receiver
maintain
identical
representations
code
case
message
lists
updated
transmission
using
move
front
heuristic
lists
initially
empty
message
transmitted
sender's
list
transmits
current
position
updates
list
moving
position
1
shifting
messages
one
position
receiver
similarly
alters
word
list
transmitted
first
time
1
position
transmitted
number
distinct
messages
transmitted
far
representation
message
must
transmitted
well
just
first
time
moved
position
one
sender
receiver
subsequent
transmission
ensemble
abcadeabfd
transmission
1
2
3
3
4
5
3
5
6
5
ease
presentation
list
positions
represented
base
ten
example
shows
algorithm
bstw
transmits
source
message
rest
transmission
consists
encodings
list
positions
therefore
essential
feature
algorithm
bstw
reasonable
scheme
representation
integers
methods
discussed
bentley
et
al
elias
codes
presented
section
3
3
simple
scheme
code
gamma
involves
prefixing
binary
representation
integer
floor
lg
zeros
yields
prefix
code
length
codeword
equal
2
floor
lg
1
greater
compression
can
gained
use
sophisticated
scheme
delta
encodes
integer
1
floor
lg
2
floor
lg
1
floor
lg
bits
message
ensemble
algorithm
bstw
particularly
efficient
described
bentley
et
al
formed
repeating
messages
times
example
1
2
3
disregarding
overhead
static
huffman
code
uses
2
lg
bits
lg
bits
per
message
algorithm
bstw
uses
2
2
sum
1
floor
lg
less
equal
2
2
lg
1
bits
per
message
overhead
algorithm
bstw
consists
just
lg
bits
needed
transmit
source
letter
discussed
section
3
2
overhead
static
huffman
coding
includes
additional
2n
bits
locality
present
ensemble
example
similar
example
transmission
effected
algorithm
bstw
1
1
2
space
3
1
1
2
4
1
1
1
2
5
1
1
1
1
2
6
1
1
1
1
1
2
7
1
1
1
1
1
1
8
1
1
1
1
1
1
1
using
3
bits
source
letter
space
elias
code
delta
list
positions
number
bits
used
81
great
improvement
methods
discussed
69
length
used
static
huffman
coding
improved
use
fibonacci
codes
list
positions
bentley
et
al
1986
proof
given
simple
scheme
encoding
integers
performance
algorithm
bstw
bounded
2
1
cost
static
huffman
coding
scheme
using
sophisticated
integer
encoding
scheme
bound
1
2
lg
1
key
idea
proofs
given
bentley
et
al
fact
using
move
front
heuristic
integer
transmitted
message
will
one
number
different
words
transmitted
since
last
occurrence
bentley
et
al
also
prove
algorithm
bstw
asymptotically
optimal
implementation
algorithm
bstw
described
great
detail
bentley
et
al
1986
implementation
encoding
integer
consists
table
lookup
codewords
integers
1
1
stored
array
indexed
1
1
binary
trie
used
store
inverse
mapping
codewords
integers
decoding
elias
codeword
find
corresponding
integer
involves
following
path
trie
two
interlinked
data
structures
binary
trie
binary
tree
used
maintain
word
list
trie
based
binary
encodings
source
words
mapping
source
message
list
position
involves
following
path
trie
following
link
tree
computing
symmetric
order
position
tree
node
finding
source
message
position
accomplished
finding
symmetric
order
position
tree
returning
word
stored
using
implementation
work
done
sender
receiver
length
length
message
transmitted
codeword
representing
's
position
list
source
alphabet
consists
single
characters
complexity
algorithm
bstw
just
length
move
front
scheme
bentley
et
al
independently
developed
elias
paper
interval
encoding
recency
rank
encoding
elias
1987
recency
rank
encoding
equivalent
algorithm
bstw
name
emphasizes
fact
mentioned
codeword
source
message
represents
number
distinct
messages
occurred
since
recent
occurrence
interval
encoding
represents
source
message
total
number
messages
occurred
since
last
occurrence
equivalently
length
interval
since
last
previous
occurrence
current
message
obvious
length
interval
since
last
occurrence
message
least
great
recency
rank
recency
rank
encoding
never
uses
generally
uses
fewer
symbols
per
message
interval
encoding
advantage
interval
encoding
simple
implementation
can
encode
decode
selections
large
alphabet
million
letters
example
microsecond
rate
elias
1987
use
interval
encoding
might
justified
data
transmission
setting
speed
essential
factor
ryabko
also
comments
work
bentley
et
al
coincides
many
results
paper
considers
data
compression
means
book
stack
books
represent
source
messages
book
occurs
taken
stack
placed
top
ryabko
1987
horspool
cormack
considered
move
front
well
several
list
organization
heuristics
connection
data
compression
horspool
cormack
1987
