computational statistics single point estimation 
methods point estimation 
ics
280
spring
1999
computational
statistics
single
point
estimators
simplest
data
model
one
just
passes
parameters
data
values
variation
observed
data
actually
noise
one
wants
kind
average
removes
noise
returns
original
value
nontrivial
elaboration
model
consider
problem
subpixel
resolution
imaging
take
one
digital
image
scene
pretty
much
stuck
pixels
image
well
can
use
bayesian
methods
get
subpixel
resolution
already
good
idea
looking
take
several
images
can
imagine
pixelations
different
applications
kind
noise
real
image
average
get
higher
resolution
image
related
problem
consensus
sequence
estimation
molecular
biology
problem
data
consists
long
sequence
characters
drawn
small
alphabet
noise
model
forms
observed
dna
sequences
prototype
sequences
mutations
another
dna
single
point
estimation
problem
reconstruction
whole
sequence
fragments
used
gene
mapping
systems
anyway
examples
high
dimension
interested
low
dimension
cases
parameter
values
really
geometric
coordinates
one
dimension
basically
two
choices
estimator
mean
median
median
obviously
much
less
sensitive
outliers
far
can
tell
even
well
behaved
error
model
gaussian
noise
median
mean
accuracy
distance
estimation
original
value
sqrt
variance
gaussian
median
better
invariance
properties
distance
free
hard
come
noise
models
mean
better
choice
two
instance
know
nothing
noise
priori
assumption
lower
variances
likely
mean
max
likelihood
estimator
minimizes
variance
differences
observation
estimate
can
easily
seen
noting
variance
unimodular
quadratic
function
estimate
computing
derivative
various
ways
generalizing
ideas
higher
dimensions
centroid
natural
generalization
mean
found
simply
computing
mean
separately
data
coordinate
alternate
way
defining
least
mean
squares
estimate
minimizes
mean
equivalently
sum
squared
distances
observation
estimate
can
seen
fact
sum
squared
distances
coordinate
can
treated
independently
coordinate
already
seen
mean
property
one
dimension
therefore
centroid
max
likelihood
estimator
settings
unknown
noise
priori
assumption
lower
variance
likely
also
inherits
accuracy
one
dimensional
mean
gaussian
noise
model
gaussian
noise
nice
property
can
generated
treating
coordinate
independently
nothing
interesting
say
algorithms
computing
centroids
fermat
weber
point
generally
one
can
define
lp
estimate
one
minimizes
sum
pth
powers
distances
observations
estimate
centroid
l2
estimate
next
commonly
used
estimate
1
estimate
also
known
fermat
weber
point
generalizes
median
since
median
minimizes
sum
distances
one
dimension
can
easily
seen
considering
derivatives
uniqueness
lp
estimate
1
follows
since
pth
power
distance
observation
strictly
convex
function
sum
strictly
convex
functions
convex
convex
function
unique
minimum
unfortunately
argument
quite
work
1
points
colinear
even
number
points
point
line
segment
two
middle
points
equal
sum
distances
exception
sure
noise
model
optimal
since
uses
lower
power
distance
less
sensitive
centroid
outliers
also
commonly
used
management
science
facility
location
central
store
location
minimizing
travel
distance
population
customers
good
combinatorial
algorithm
fermat
weber
point
since
exact
location
solution
high
degree
polynomial
observation's
coordinates
b88
cm69
however
gradient
descent
methods
converge
rapidly
give
good
numerical
approximations
location
w37
circumcenter
limit
goes
infinity
pth
root
sum
pth
powers
distances
just
maximum
distances
limit
lp
estimators
linfinity
estimator
minimizes
maximum
distance
observation
data
point
one
draws
circle
sphere
around
estimate
radius
equal
distance
contains
data
points
smaller
circle
sphere
contains
points
estimate
also
called
circumcenter
extremely
sensitive
outliers
usually
provide
good
estimator
one
can
imagine
conditions
appropriate
choice
know
nothing
noise
noisy
observation
within
unknown
bounded
radius
true
estimate
circumcenter
accurate
estimator
maximum
distance
true
data
value
half
noise
radius
exist
several
linear
time
algorithms
computing
circumcenter
collection
data
points
based
linear
programming
type
techniques
problem
linear
program
can
solved
much
algorithms
g95
current
best
time
bounds
form
d2
log
subexponential
function
dimension
affect
main
term
running
time
bernd
rtner
good
well
documented
implementation
available
g99
can
solve
problems
hundreds
thousands
points
dimension
20
30
centerpoint
point
set
center
point
point
halfspace
contain
can
contain
constant
fraction
dn
1
observations
equivalently
halfspace
containing
contains
least
1
observations
proof
see
abet98
section
2
5
provides
robust
distance
free
method
estimation
1
1
observations
outliers
chosen
adversary
fool
algorithm
estimate
must
within
convex
hull
remaining
points
therefore
strongly
affected
outliers
center
points
also
applications
within
computational
geometry
finding
graph
separators
applications
mesh
partitioning
intersection
graph
construction
etc
emt95
points
plane
centerpoint
can
computed
linear
time
points
three
dimensions
time
polylog
citations
filled
later
higher
dimensions
best
known
time
bound
much
slower
nd
1
however
exists
fast
approximation
algorithm
citation
filled
later
smallest
subset
methods
least
median
squares
one
takes
primary
aim
robustness
one
can
even
better
centerpoint
maximum
number
outliers
one
hope
detect
floor
1
2
half
observations
outliers
way
principle
distinguish
outlying
half
data
unperturbed
half
one
can
tolerate
exactly
many
outliers
one
uses
method
finds
subset
ceiling
1
2
points
minimizes
various
functionals
circumradius
variance
convex
hull
area
non
outlying
observations
form
small
subset
functionals
subset
must
include
least
one
non
outlier
can
small
also
near
unperturbed
data
good
question
discussion
functional
appropriate
optimize
noise
models
version
one
minimizes
circumradius
also
called
least
median
squares
minimizes
median
squared
distance
observation
estimate
various
algorithms
known
problems
work
gone
variants
cardinality
selected
subset
small
case
better
viewed
form
clustering
robust
estimation
ee94
large
tolerant
small
number
outliers
often
possible
show
problems
like
optimal
solution
consists
nearest
neighbors
estimated
center
point
instance
least
median
squares
problem
optimal
subset
consists
nearest
neighbors
optimal
subset's
circumcenter
similarly
element
subset
minimizing
variance
consists
points
nearest
optimal
subset's
median
obviously
know
center
point
advance
need
use
estimation
algorithm
one
can
use
idea
limit
number
subsets
examine
order
voronoi
diagram
essentially
encapsulates
family
possible
subsets
defined
partition
space
cells
two
points
cell
set
nearest
neighbors
plane
diagram
known
kn
cells
can
constructed
time
log
kn
2o
log
r99
variance
one
cell
can
updated
neighbor
constant
time
minimum
variance
element
subset
can
found
time
bound
nearly
quadratic
statistically
relevant
case
roughly
2
computing
diagrams
certain
subsets
points
one
can
remove
2o
log
factor
little
smaller
ee94
idea
works
least
median
squares
slower
difficult
update
circumradius
one
moves
cell
cell
e92
instead
fastest
known
algorithms
use
parametric
search
complicated
variant
binary
search
based
decision
algorithm
tests
given
circle
radius
finding
largest
subset
points
fit
within
radius
decision
problem
can
solved
drawing
circle
given
radius
around
point
building
arrangement
circles
computing
many
circles
surround
cell
constant
time
per
cell
adding
subtracting
one
value
neighboring
cell
best
time
bounds
roughly
2
improvement
possible
smaller
n2
log
2
nd
log2n
2
ee94
distance
function
use
assumed
distance
two
points
measured
using
normal
euclidean
distance
square
difference
coordinate
sum
squares
take
square
root
sum
seems
assumption
based
choice
noise
model
assume
priori
centrally
symmetric
noise
distribution
assume
noise
coordinate
independent
gaussian
case
overall
distribution
ends
centrally
symmetric
euclidean
distance
makes
sense
otherwise
seems
choose
distance
function
determined
probability
data
point
actually
perturbed
measure
reason
expect
distance
function
obey
axioms
metric
way
well
behaved
perhaps
fact
avoid
choose
distance
function
one
things
makes
distance
free
methods
centerpoint
attractive
next
linear
regression
david
eppstein
theory
group
dept
information
computer
science
uc
irvine
last
update
12
may
1999
11
21
03
pdt
